#!/usr/bin/env python3
"""
Code Analyzer - Migration Tools

Analyse le code existant utilisant DAG pour identifier automatiquement
les opportunit√©s de migration vers EnhancedDAG.

FONCTIONNALIT√âS:
1. D√©tection patterns DAG originaux
2. Identification complexit√© √©vitable
3. Suggestions migration sp√©cifiques
4. Estimation b√©n√©fices migration
5. G√©n√©ration rapports analyse

Usage:
    python code_analyzer.py [--path CODE_PATH] [--output REPORT_PATH]
"""

import ast
import os
import re
import argparse
import json
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass, asdict
from pathlib import Path


@dataclass
class MigrationOpportunity:
    """Repr√©sente une opportunit√© de migration identifi√©e"""
    file_path: str
    line_number: int
    pattern_type: str
    description: str
    complexity_before: int
    complexity_after: int
    confidence: float
    suggested_replacement: str
    estimated_benefit: str


@dataclass
class AnalysisReport:
    """Rapport complet d'analyse migration"""
    analyzed_files: int
    total_opportunities: int
    high_confidence_opportunities: int
    estimated_total_benefit: Dict[str, int]
    opportunities_by_type: Dict[str, int]
    detailed_opportunities: List[MigrationOpportunity]


class DAGCodeAnalyzer(ast.NodeVisitor):
    """Analyseur AST pour identifier patterns DAG"""

    def __init__(self, file_path: str):
        self.file_path = file_path
        self.opportunities = []
        self.current_line = 0
        self.dag_imports = set()
        self.dag_instances = set()

    def visit(self, node):
        """Visit AST node avec tracking num√©ro ligne"""
        if hasattr(node, 'lineno'):
            self.current_line = node.lineno
        super().visit(node)

    def visit_Import(self, node):
        """D√©tecte imports DAG"""
        for alias in node.names:
            if 'dag' in alias.name.lower() or 'icgs' in alias.name.lower():
                self.dag_imports.add(alias.name)

    def visit_ImportFrom(self, node):
        """D√©tecte imports from DAG"""
        if node.module and ('dag' in node.module.lower() or 'icgs' in node.module.lower()):
            for alias in node.names:
                self.dag_imports.add(alias.name)

    def visit_Call(self, node):
        """D√©tecte appels m√©thodes DAG probl√©matiques"""

        # Pattern 1: DAG() construction
        if isinstance(node.func, ast.Name) and node.func.id == 'DAG':
            self.opportunities.append(MigrationOpportunity(
                file_path=self.file_path,
                line_number=self.current_line,
                pattern_type="dag_construction",
                description="Construction DAG peut √™tre simplifi√©e avec EnhancedDAG",
                complexity_before=3,
                complexity_after=1,
                confidence=0.9,
                suggested_replacement="enhanced_dag = EnhancedDAG(config)",
                estimated_benefit="Configuration simplifi√©e"
            ))

        # Pattern 2: update_taxonomy avec boucle
        if (isinstance(node.func, ast.Attribute) and
            node.func.attr == 'update_taxonomy'):

            self.opportunities.append(MigrationOpportunity(
                file_path=self.file_path,
                line_number=self.current_line,
                pattern_type="update_taxonomy",
                description="update_taxonomy peut √™tre remplac√© par configure_accounts_simple",
                complexity_before=5,
                complexity_after=1,
                confidence=0.85,
                suggested_replacement="enhanced_dag.configure_accounts_simple(accounts)",
                estimated_benefit="√âlimination boucle manuelle transaction_num"
            ))

        # Pattern 3: get_character_mapping avec transaction_num
        if (isinstance(node.func, ast.Attribute) and
            node.func.attr == 'get_character_mapping' and
            len(node.args) >= 2):

            self.opportunities.append(MigrationOpportunity(
                file_path=self.file_path,
                line_number=self.current_line,
                pattern_type="character_mapping_access",
                description="Acc√®s mapping peut √™tre simplifi√© sans transaction_num",
                complexity_before=2,
                complexity_after=1,
                confidence=0.8,
                suggested_replacement="enhanced_dag.get_current_account_mapping(account_id)",
                estimated_benefit="√âlimination gestion manuelle transaction_num"
            ))

        # Pattern 4: convert_path_to_word avec transaction_num
        if (isinstance(node.func, ast.Attribute) and
            node.func.attr == 'convert_path_to_word' and
            len(node.args) >= 2):

            self.opportunities.append(MigrationOpportunity(
                file_path=self.file_path,
                line_number=self.current_line,
                pattern_type="path_conversion",
                description="Conversion path peut √™tre simplifi√©e sans transaction_num",
                complexity_before=2,
                complexity_after=1,
                confidence=0.8,
                suggested_replacement="enhanced_dag.convert_path_simple(path)",
                estimated_benefit="API simplifi√©e conversion paths"
            ))

        self.generic_visit(node)

    def visit_For(self, node):
        """D√©tecte boucles transaction_num"""
        # D√©tection pattern: for tx_num in range(...)
        if (isinstance(node.target, ast.Name) and
            'tx' in node.target.id.lower() and 'num' in node.target.id.lower()):

            self.opportunities.append(MigrationOpportunity(
                file_path=self.file_path,
                line_number=self.current_line,
                pattern_type="transaction_num_loop",
                description="Boucle transaction_num peut √™tre √©limin√©e avec API simplifi√©e",
                complexity_before=8,
                complexity_after=2,
                confidence=0.9,
                suggested_replacement="# Boucle remplac√©e par configure_accounts_simple()",
                estimated_benefit="√âlimination logique complexe transaction_num"
            ))

        self.generic_visit(node)


class MigrationAnalyzer:
    """Analyseur principal migration"""

    def __init__(self):
        self.total_files_analyzed = 0
        self.all_opportunities = []

    def analyze_file(self, file_path: str) -> List[MigrationOpportunity]:
        """Analyse un fichier Python pour opportunit√©s migration"""

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                source_code = f.read()

            # Parse AST
            tree = ast.parse(source_code)

            # Analyse AST
            analyzer = DAGCodeAnalyzer(file_path)
            analyzer.visit(tree)

            # Analyse textuelle additionnelle
            text_opportunities = self._analyze_text_patterns(file_path, source_code)

            all_opportunities = analyzer.opportunities + text_opportunities
            self.all_opportunities.extend(all_opportunities)

            return all_opportunities

        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur analyse {file_path}: {e}")
            return []

    def _analyze_text_patterns(self, file_path: str, source_code: str) -> List[MigrationOpportunity]:
        """Analyse patterns textuels compl√©mentaires"""
        opportunities = []
        lines = source_code.split('\n')

        for line_num, line in enumerate(lines, 1):
            # Pattern: Commentaires indiquant complexit√© DAG
            if re.search(r'#.*(?:complex|difficult|transaction.*num)', line, re.IGNORECASE):
                opportunities.append(MigrationOpportunity(
                    file_path=file_path,
                    line_number=line_num,
                    pattern_type="complexity_comment",
                    description="Commentaire indique complexit√© pouvant √™tre r√©duite",
                    complexity_before=3,
                    complexity_after=1,
                    confidence=0.6,
                    suggested_replacement="# Simplifi√© avec EnhancedDAG",
                    estimated_benefit="R√©duction complexit√© cognitive"
                ))

            # Pattern: Variables transaction_num multiples
            if re.search(r'tx_num.*=|transaction_num.*=', line):
                opportunities.append(MigrationOpportunity(
                    file_path=file_path,
                    line_number=line_num,
                    pattern_type="transaction_num_variable",
                    description="Gestion manuelle transaction_num d√©tect√©e",
                    complexity_before=2,
                    complexity_after=0,
                    confidence=0.7,
                    suggested_replacement="# Auto-g√©r√© par EnhancedDAG",
                    estimated_benefit="√âlimination gestion manuelle"
                ))

        return opportunities

    def analyze_directory(self, directory_path: str, recursive: bool = True) -> AnalysisReport:
        """Analyse r√©pertoire complet"""

        python_files = []

        if recursive:
            for root, dirs, files in os.walk(directory_path):
                # Skip __pycache__ et .git
                dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']

                for file in files:
                    if file.endswith('.py'):
                        python_files.append(os.path.join(root, file))
        else:
            for file in os.listdir(directory_path):
                if file.endswith('.py'):
                    python_files.append(os.path.join(directory_path, file))

        print(f"üîç Analyse {len(python_files)} fichiers Python...")

        # Analyse tous les fichiers
        for file_path in python_files:
            print(f"   Analyse: {file_path}")
            self.analyze_file(file_path)
            self.total_files_analyzed += 1

        # G√©n√©ration rapport
        return self._generate_report()

    def _generate_report(self) -> AnalysisReport:
        """G√©n√®re rapport complet d'analyse"""

        # Classification opportunit√©s
        high_confidence = [opp for opp in self.all_opportunities if opp.confidence >= 0.8]

        # Groupement par type
        by_type = {}
        for opp in self.all_opportunities:
            by_type[opp.pattern_type] = by_type.get(opp.pattern_type, 0) + 1

        # Calcul b√©n√©fices estim√©s
        total_complexity_reduction = sum(opp.complexity_before - opp.complexity_after
                                       for opp in self.all_opportunities)

        estimated_benefits = {
            'complexity_reduction_points': total_complexity_reduction,
            'lines_of_code_saved': len([opp for opp in self.all_opportunities
                                      if opp.pattern_type in ['transaction_num_loop', 'dag_construction']]),
            'error_prone_patterns_eliminated': len([opp for opp in self.all_opportunities
                                                  if opp.pattern_type in ['update_taxonomy', 'transaction_num_loop']]),
        }

        return AnalysisReport(
            analyzed_files=self.total_files_analyzed,
            total_opportunities=len(self.all_opportunities),
            high_confidence_opportunities=len(high_confidence),
            estimated_total_benefit=estimated_benefits,
            opportunities_by_type=by_type,
            detailed_opportunities=self.all_opportunities
        )

    def save_report(self, report: AnalysisReport, output_path: str):
        """Sauvegarde rapport au format JSON"""

        # Conversion en dict pour s√©rialisation
        report_dict = asdict(report)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report_dict, f, indent=2, ensure_ascii=False)

        print(f"‚úÖ Rapport sauvegard√©: {output_path}")

    def print_summary(self, report: AnalysisReport):
        """Affiche r√©sum√© analyse"""

        print(f"\nüìä ANALYSE MIGRATION - R√âSUM√â")
        print("=" * 50)
        print(f"Fichiers analys√©s:           {report.analyzed_files}")
        print(f"Opportunit√©s totales:        {report.total_opportunities}")
        print(f"Haute confiance (‚â•80%):      {report.high_confidence_opportunities}")

        print(f"\nüìà B√âN√âFICES ESTIM√âS:")
        benefits = report.estimated_total_benefit
        print(f"  R√©duction complexit√©:      {benefits['complexity_reduction_points']} points")
        print(f"  Lignes code √©conomis√©es:   {benefits['lines_of_code_saved']}")
        print(f"  Patterns risqu√©s √©limin√©s: {benefits['error_prone_patterns_eliminated']}")

        print(f"\nüéØ OPPORTUNIT√âS PAR TYPE:")
        for pattern_type, count in report.opportunities_by_type.items():
            print(f"  {pattern_type}: {count}")

        if report.high_confidence_opportunities > 0:
            print(f"\n‚úÖ RECOMMANDATION: PROC√âDER MIGRATION")
            print(f"   {report.high_confidence_opportunities} opportunit√©s haute confiance d√©tect√©es")
        else:
            print(f"\n‚ö†Ô∏è  RECOMMANDATION: √âVALUER MANUELLEMENT")
            print(f"   Opportunit√©s d√©tect√©es mais n√©cessitent validation")


def main():
    """Interface ligne commande"""

    parser = argparse.ArgumentParser(
        description="Analyse code DAG pour opportunit√©s migration EnhancedDAG"
    )

    parser.add_argument(
        '--path', '-p',
        default='.',
        help="Chemin code √† analyser (d√©faut: r√©pertoire courant)"
    )

    parser.add_argument(
        '--output', '-o',
        default='migration_analysis_report.json',
        help="Chemin rapport sortie (d√©faut: migration_analysis_report.json)"
    )

    parser.add_argument(
        '--recursive', '-r',
        action='store_true',
        help="Analyse r√©cursive sous-r√©pertoires"
    )

    parser.add_argument(
        '--detailed', '-d',
        action='store_true',
        help="Affichage d√©taill√© opportunit√©s"
    )

    args = parser.parse_args()

    print("üöÄ ANALYSEUR MIGRATION DAG ‚Üí EnhancedDAG")
    print("=" * 60)

    # Validation chemin
    if not os.path.exists(args.path):
        print(f"‚ùå Erreur: Chemin {args.path} n'existe pas")
        return 1

    # Analyse
    analyzer = MigrationAnalyzer()

    if os.path.isfile(args.path):
        # Analyse fichier unique
        opportunities = analyzer.analyze_file(args.path)
        analyzer.total_files_analyzed = 1
        report = analyzer._generate_report()
    else:
        # Analyse r√©pertoire
        report = analyzer.analyze_directory(args.path, args.recursive)

    # Affichage r√©sum√©
    analyzer.print_summary(report)

    # Affichage d√©taill√© si demand√©
    if args.detailed and report.detailed_opportunities:
        print(f"\nüîç OPPORTUNIT√âS D√âTAILL√âES:")
        print("-" * 60)

        for i, opp in enumerate(report.detailed_opportunities[:10], 1):  # Limiter √† 10
            print(f"{i}. {opp.file_path}:{opp.line_number}")
            print(f"   Type: {opp.pattern_type}")
            print(f"   Description: {opp.description}")
            print(f"   Confiance: {opp.confidence:.0%}")
            print(f"   Suggestion: {opp.suggested_replacement}")
            print()

        if len(report.detailed_opportunities) > 10:
            print(f"   ... et {len(report.detailed_opportunities) - 10} autres opportunit√©s")

    # Sauvegarde rapport
    analyzer.save_report(report, args.output)

    return 0


if __name__ == "__main__":
    exit(main())