#!/usr/bin/env python3
"""
DIAGNOSTIC MODE THINK: Analyser "no paths were classified"
Pipeline path enumeration ‚Üí classification cass√©
"""

import unittest
from decimal import Decimal
import sys
import os

# Path setup pour import modules
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from icgs_core.dag import DAG, Transaction, TransactionMeasure


class TestDiagnosticNoPathsClassified(unittest.TestCase):
    """Diagnostic complet pipeline classification"""

    def test_diagnostic_pipeline_step_by_step(self):
        """Diagnostic √©tape par √©tape du pipeline"""
        print("\n=== DIAGNOSTIC PIPELINE CLASSIFICATION ===")

        # Setup DAG avec taxonomie Test 16 probl√©matique
        dag = DAG()

        # Taxonomie UTF-32 grecque identique √† Test 16
        node_mappings = {
            "account_source_0_source": "Œ©",  # Pour pattern .*Œ©.*
            "account_source_0_sink": "Œ®",
            "account_target_0_source": "Œß",  # Pour pattern .*Œß.*
            "account_target_0_sink": "Œ¶"
        }

        dag.account_taxonomy.update_taxonomy(node_mappings, 0)
        print(f"‚úÖ Taxonomie configur√©e avec {len(node_mappings)} mappings")

        # Transaction probl√©matique identique Test 16
        transaction = Transaction(
            transaction_id="diagnostic_tx",
            source_account_id="account_source_0",
            target_account_id="account_target_0",
            amount=Decimal('100'),
            source_measures=[
                TransactionMeasure(
                    measure_id="measure_source_0",
                    account_id="account_source_0",
                    primary_regex_pattern=".*Œ©.*",  # Pattern pour Œ©
                    primary_regex_weight=Decimal('1.0'),
                    acceptable_value=Decimal('500')
                )
            ],
            target_measures=[
                TransactionMeasure(
                    measure_id="measure_target_0",
                    account_id="account_target_0",
                    primary_regex_pattern=".*Œß.*",  # Pattern pour Œß
                    primary_regex_weight=Decimal('1.0'),
                    acceptable_value=Decimal('0'),
                    required_value=Decimal('50')
                )
            ]
        )

        print(f"Transaction: {transaction.transaction_id}")
        print(f"  Source patterns: {[m.primary_regex_pattern for m in transaction.source_measures]}")
        print(f"  Target patterns: {[m.primary_regex_pattern for m in transaction.target_measures]}")

        # √âTAPE 1: Cr√©ation comptes
        print("\n--- √âTAPE 1: CR√âATION COMPTES ---")
        try:
            dag._ensure_accounts_exist_with_taxonomy(transaction)
            print(f"‚úÖ Comptes cr√©√©s: {list(dag.accounts.keys())}")

            # V√©rifier mappings taxonomie
            for account_id in transaction.source_account_id, transaction.target_account_id:
                account = dag.accounts[account_id]
                source_char = dag.account_taxonomy.get_character_mapping(account.source_node.node_id, 0)
                sink_char = dag.account_taxonomy.get_character_mapping(account.sink_node.node_id, 0)
                print(f"  {account_id}: source='{source_char}', sink='{sink_char}'")

        except Exception as e:
            print(f"‚ùå Erreur cr√©ation comptes: {e}")
            return

        # √âTAPE 2: Cr√©ation NFA temporaire
        print("\n--- √âTAPE 2: CR√âATION NFA ---")
        try:
            temp_nfa = dag._create_temporary_nfa_for_transaction(transaction)
            print(f"‚úÖ NFA cr√©√©: {len(temp_nfa.get_final_states())} √©tats finaux")

            # Test patterns dans NFA avec API correcte
            test_words = ["Œ©", "Œß", "Œ©Œß", "ŒßŒ©", "Œ®Œ¶"]
            print("Test patterns NFA:")
            for test_word in test_words:
                try:
                    if hasattr(temp_nfa, 'evaluate_to_final_state'):
                        result = temp_nfa.evaluate_to_final_state(test_word)
                        print(f"  '{test_word}' ‚Üí {result} (evaluate_to_final_state)")
                    elif hasattr(temp_nfa, 'evaluate_word'):
                        result = temp_nfa.evaluate_word(test_word)
                        print(f"  '{test_word}' ‚Üí {result} (evaluate_word)")
                    else:
                        print(f"  '{test_word}' ‚Üí No evaluation method found")
                except Exception as e:
                    print(f"  '{test_word}' ‚Üí ERROR: {e}")

        except Exception as e:
            print(f"‚ùå Erreur cr√©ation NFA: {e}")
            return

        # √âTAPE 3: Cr√©ation transaction edge
        print("\n--- √âTAPE 3: TRANSACTION EDGE ---")
        try:
            temp_edge = dag._create_temporary_transaction_edge(transaction)
            print(f"‚úÖ Edge cr√©√©: {temp_edge.source_node.node_id} ‚Üí {temp_edge.target_node.node_id}")

        except Exception as e:
            print(f"‚ùå Erreur transaction edge: {e}")
            return

        # √âTAPE 4: Path enumeration
        print("\n--- √âTAPE 4: PATH ENUMERATION ---")
        try:
            # Acc√®s direct au path enumerator
            paths = list(dag.path_enumerator.enumerate_paths_from_transaction(temp_edge, 0))
            print(f"‚úÖ Paths √©num√©r√©s: {len(paths)}")

            if paths:
                for i, path in enumerate(paths[:3]):  # Premier 3 paths
                    path_nodes = [node.node_id for node in path]
                    print(f"  Path {i}: {path_nodes}")
            else:
                print("‚ùå PROBL√àME: Aucun path √©num√©r√©!")
                return

        except Exception as e:
            print(f"‚ùå Erreur path enumeration: {e}")
            return

        # √âTAPE 5: Path ‚Üí Word conversion
        print("\n--- √âTAPE 5: PATH ‚Üí WORD CONVERSION ---")
        try:
            words = dag.path_enumerator.convert_paths_to_words(paths, 0)
            print(f"‚úÖ Words g√©n√©r√©s: {len(words)}")

            for i, (path, word) in enumerate(zip(paths[:3], words[:3])):
                path_nodes = [node.node_id for node in path]
                print(f"  Path {i}: {path_nodes} ‚Üí '{word}'")

        except Exception as e:
            print(f"‚ùå Erreur path‚Üíword: {e}")
            return

        # √âTAPE 6: NFA classification
        print("\n--- √âTAPE 6: NFA CLASSIFICATION ---")
        try:
            classifications = {}
            classified_count = 0

            for i, (path, word) in enumerate(zip(paths, words)):
                if word:
                    try:
                        # Utiliser m√™me API que path_enumerator
                        final_state_id = None
                        if hasattr(temp_nfa, 'evaluate_to_final_state'):
                            final_state_id = temp_nfa.evaluate_to_final_state(word)
                        elif hasattr(temp_nfa, 'evaluate_word'):
                            result = temp_nfa.evaluate_word(word)
                            final_state_id = result[0] if isinstance(result, tuple) else result

                        if final_state_id:
                            if final_state_id not in classifications:
                                classifications[final_state_id] = []
                            classifications[final_state_id].append(path)
                            classified_count += 1
                            if i < 3:  # Log premier 3
                                print(f"  Word '{word}' ‚Üí state '{final_state_id}' ‚úÖ")
                        else:
                            if i < 3:
                                print(f"  Word '{word}' ‚Üí NO MATCH ‚ùå")
                    except Exception as e:
                        if i < 3:
                            print(f"  Word '{word}' ‚Üí ERROR: {e}")

            print(f"\nüìä R√âSULTAT CLASSIFICATION:")
            print(f"  Total paths: {len(paths)}")
            print(f"  Paths classifi√©s: {classified_count}")
            print(f"  Taux classification: {(classified_count/len(paths)*100) if paths else 0:.1f}%")
            print(f"  √âtats trouv√©s: {len(classifications)}")

            if classified_count == 0:
                print(f"\n‚ùå PROBL√àME IDENTIFI√â: AUCUNE CLASSIFICATION")
                print(f"   ‚Üí Patterns NFA ne matchent pas mots g√©n√©r√©s")
                print(f"   ‚Üí V√©rifier alignment patterns ‚Üî caract√®res taxonomie")
            else:
                print(f"\n‚úÖ Classification r√©ussie partiellement")

        except Exception as e:
            print(f"‚ùå Erreur classification NFA: {e}")

        # √âTAPE 7: Diagnostic complet pipeline
        print("\n--- DIAGNOSTIC FINAL ---")
        try:
            result = dag.path_enumerator.enumerate_and_classify(temp_edge, temp_nfa, 0)
            print(f"Pipeline complet result: {type(result)}")

            if isinstance(result, dict):
                total_classified = sum(len(paths) for paths in result.values())
                print(f"  Classifications: {len(result)} √©tats")
                print(f"  Paths classifi√©s: {total_classified}")

                if total_classified == 0:
                    print(f"  ‚ùå CONFIRM√â: Pipeline retourne classifications vides")
                else:
                    print(f"  ‚úÖ Pipeline fonctionne partiellement")

        except Exception as e:
            print(f"‚ùå Erreur pipeline complet: {e}")

        self.assertTrue(True, "Diagnostic termin√©")


if __name__ == '__main__':
    unittest.main(verbosity=2)