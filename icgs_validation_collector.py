"""
ICGS Validation Data Collector - Capture M√©triques R√©elles Pipeline

Module pour capturer et stocker les m√©triques de validation r√©elles du pipeline
ICGS (_validate_transaction_simplex) pour synchronisation avec visualisations SVG.

Objectif : Remplacer donn√©es mock statiques par m√©triques authentiques :
- Vertices : Classes d'√©quivalence chemins DAG
- Constraints : Contraintes LP construites
- Algorithm Steps : It√©rations Simplex r√©elles
- Coordinates : Variables solution optimale
- Status : √âtat r√©solution validation

Architecture non-invasive avec cache LRU pour performance.
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple
from decimal import Decimal
import time
import logging
from functools import lru_cache

# Import des modules ICGS pour types avec gestion d'erreur robuste
try:
    from icgs_core.simplex_solver import SimplexSolution, SolutionStatus
    from icgs_core.linear_programming import LinearProgram
    ICGS_CORE_TYPES_AVAILABLE = True
    logging.info("‚úÖ ICGS core types imported successfully in ValidationDataCollector")
except ImportError as e:
    # Fallback: d√©finir types minimaux pour compatibilit√©
    logging.error(f"‚ùå ICGS core types import failed: {e}")
    ICGS_CORE_TYPES_AVAILABLE = False

    # Types fallback
    class SolutionStatus:
        FEASIBLE = "FEASIBLE"
        INFEASIBLE = "INFEASIBLE"
        UNBOUNDED = "UNBOUNDED"
        UNKNOWN = "UNKNOWN"

    class SimplexSolution:
        def __init__(self):
            self.status = SolutionStatus.UNKNOWN
            self.iterations_used = 0
            self.variables = {}
            self.warm_start_successful = False
            self.cross_validation_passed = False

    class LinearProgram:
        def __init__(self):
            self.constraints = []

logger = logging.getLogger(__name__)


@dataclass
class SimplexMetrics:
    """M√©triques r√©elles d'une validation Simplex pour transaction donn√©e"""
    transaction_num: int
    transaction_id: str

    # M√©triques pipeline validation (remplacent mocks)
    vertices_count: int                     # len(path_classes) - Classes √©quivalence DAG
    constraints_count: int                  # len(lp_problem.constraints) - Contraintes LP
    algorithm_steps: int                    # solution.iterations_used - It√©rations r√©elles

    # Coordonn√©es optimales (remplacent calculs arbitraires)
    optimal_coordinates: List[float]        # solution.variables values
    optimal_value: float                    # Valeur objective

    # Status et m√©tadonn√©es validation
    solution_status: SolutionStatus         # FEASIBLE/INFEASIBLE/UNBOUNDED
    warm_start_used: bool                   # Pivot r√©utilis√©
    cross_validation_passed: bool           # Triple validation r√©ussie

    # Performance metrics
    enumeration_time_ms: float              # Temps √©num√©ration chemins
    simplex_solve_time_ms: float            # Temps r√©solution LP

    # Timestamp capture
    capture_time: float = field(default_factory=time.time)


@dataclass
class ValidationPipelineState:
    """√âtat complet pipeline validation pour debugging/analysis"""
    path_classes: Dict[str, List[List[Any]]]  # Classes √©quivalence chemins
    lp_problem: LinearProgram                 # Probl√®me LP construit
    simplex_solution: SimplexSolution         # Solution Simplex compl√®te

    # M√©tadonn√©es NFA
    nfa_final_states_count: int
    nfa_frozen: bool


class ValidationDataCollector:
    """
    Collecteur de donn√©es validation ICGS - Interface non-invasive

    Capture les m√©triques r√©elles du pipeline _validate_transaction_simplex
    et les met en cache pour utilisation par API SVG.

    Architecture thread-safe avec cache LRU pour performance.
    """

    def __init__(self, cache_size: int = 100):
        """
        Initialise collecteur avec cache configurable

        Args:
            cache_size: Taille cache LRU pour m√©triques
        """
        self.cache_size = cache_size
        self._metrics_cache: Dict[int, SimplexMetrics] = {}
        self._pipeline_states: Dict[int, ValidationPipelineState] = {}

        # Statistiques collecteur
        self.stats = {
            'captures_performed': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'last_capture_time': None
        }

        logger.info(f"ValidationDataCollector initialized with cache_size={cache_size}")

    def capture_simplex_metrics(self,
                               transaction_num: int,
                               transaction_id: str,
                               path_classes: Dict[str, List[List[Any]]],
                               lp_problem: LinearProgram,
                               simplex_solution: SimplexSolution,
                               enumeration_time_ms: float,
                               simplex_solve_time_ms: float,
                               nfa_final_states_count: int = 0) -> SimplexMetrics:
        """
        Capture m√©triques compl√®tes validation pour transaction

        Appel√© depuis _validate_transaction_simplex apr√®s r√©solution r√©ussie.

        Args:
            transaction_num: Num√©ro transaction (1-33)
            transaction_id: ID unique transaction
            path_classes: Classes √©quivalence chemins DAG
            lp_problem: Probl√®me LP construit
            simplex_solution: Solution Simplex compl√®te
            enumeration_time_ms: Temps √©num√©ration chemins
            simplex_solve_time_ms: Temps r√©solution LP
            nfa_final_states_count: Nombre √©tats finaux NFA

        Returns:
            SimplexMetrics: M√©triques captur√©es et mises en cache
        """
        try:
            logger.info(f"üìä capture_simplex_metrics called: tx_num={transaction_num}, tx_id={transaction_id}")

            # Extraction m√©triques depuis objets r√©els avec gestion d√©fensive
            vertices_count = len(path_classes) if path_classes and hasattr(path_classes, '__len__') else 0
            constraints_count = len(lp_problem.constraints) if lp_problem and hasattr(lp_problem, 'constraints') and lp_problem.constraints else 0
            algorithm_steps = getattr(simplex_solution, 'iterations_used', 0) if simplex_solution else 0

            logger.info(f"üìä Extracted basic metrics: vertices={vertices_count}, constraints={constraints_count}, steps={algorithm_steps}")

            # Coordonn√©es optimales depuis solution r√©elle
            optimal_coordinates = []
            optimal_value = 0.0

            if simplex_solution and hasattr(simplex_solution, 'variables') and simplex_solution.variables:
                try:
                    # Extraction variables solution (format Decimal ‚Üí float)
                    optimal_coordinates = [
                        float(value) for value in simplex_solution.variables.values()
                    ]
                    logger.info(f"üìä Extracted coordinates: {len(optimal_coordinates)} variables")
                except Exception as coord_error:
                    logger.warning(f"‚ö†Ô∏è Failed to extract coordinates: {coord_error}")

                # Valeur objective si disponible
                if hasattr(simplex_solution, 'objective_value'):
                    try:
                        optimal_value = float(simplex_solution.objective_value)
                    except Exception:
                        optimal_value = 0.0

            # Construction metrics compl√®tes
            metrics = SimplexMetrics(
                transaction_num=transaction_num,
                transaction_id=transaction_id,
                vertices_count=vertices_count,
                constraints_count=constraints_count,
                algorithm_steps=algorithm_steps,
                optimal_coordinates=optimal_coordinates,
                optimal_value=optimal_value,
                solution_status=simplex_solution.status if simplex_solution else SolutionStatus.UNKNOWN,
                warm_start_used=simplex_solution.warm_start_successful if simplex_solution else False,
                cross_validation_passed=simplex_solution.cross_validation_passed if simplex_solution else False,
                enumeration_time_ms=enumeration_time_ms,
                simplex_solve_time_ms=simplex_solve_time_ms
            )

            # Stockage cache avec √©viction LRU
            self._store_in_cache(transaction_num, metrics)

            # Stockage √©tat pipeline complet pour debugging
            if path_classes and lp_problem and simplex_solution:
                pipeline_state = ValidationPipelineState(
                    path_classes=path_classes,
                    lp_problem=lp_problem,
                    simplex_solution=simplex_solution,
                    nfa_final_states_count=nfa_final_states_count,
                    nfa_frozen=True  # NFA toujours frozen dans pipeline
                )
                self._pipeline_states[transaction_num] = pipeline_state

            # Statistiques
            self.stats['captures_performed'] += 1
            self.stats['last_capture_time'] = time.time()

            logger.debug(f"Captured validation metrics for transaction {transaction_num}: "
                        f"vertices={vertices_count}, constraints={constraints_count}, steps={algorithm_steps}")

            return metrics

        except Exception as e:
            logger.error(f"Failed to capture simplex metrics for transaction {transaction_num}: {e}")
            # Retourner m√©triques par d√©faut en cas d'erreur
            return self._create_fallback_metrics(transaction_num, transaction_id)

    def get_cached_validation_data(self, transaction_num: int) -> Optional[SimplexMetrics]:
        """
        R√©cup√®re donn√©es validation mises en cache

        Args:
            transaction_num: Num√©ro transaction (1-33)

        Returns:
            SimplexMetrics si disponible en cache, None sinon
        """
        if transaction_num in self._metrics_cache:
            self.stats['cache_hits'] += 1
            logger.debug(f"Cache hit for transaction {transaction_num}")
            return self._metrics_cache[transaction_num]
        else:
            self.stats['cache_misses'] += 1
            logger.debug(f"Cache miss for transaction {transaction_num}")
            return None

    def get_pipeline_state(self, transaction_num: int) -> Optional[ValidationPipelineState]:
        """
        R√©cup√®re √©tat pipeline complet pour debugging

        Args:
            transaction_num: Num√©ro transaction

        Returns:
            ValidationPipelineState si disponible, None sinon
        """
        return self._pipeline_states.get(transaction_num)

    def clear_cache(self) -> None:
        """Vide cache complet pour lib√©rer m√©moire"""
        self._metrics_cache.clear()
        self._pipeline_states.clear()
        logger.info("Validation data cache cleared")

    def get_statistics(self) -> Dict[str, Any]:
        """
        Retourne statistiques collecteur

        Returns:
            Dict avec m√©triques performance et utilisation cache
        """
        return {
            **self.stats,
            'cache_size': len(self._metrics_cache),
            'pipeline_states_stored': len(self._pipeline_states),
            'cache_hit_rate': (
                self.stats['cache_hits'] / (self.stats['cache_hits'] + self.stats['cache_misses'])
                if (self.stats['cache_hits'] + self.stats['cache_misses']) > 0 else 0.0
            )
        }

    def _store_in_cache(self, transaction_num: int, metrics: SimplexMetrics) -> None:
        """Stockage cache avec √©viction LRU"""
        # √âviction si cache plein
        if len(self._metrics_cache) >= self.cache_size:
            # Supprimer entr√©e la plus ancienne (approximation LRU simple)
            oldest_key = min(self._metrics_cache.keys(),
                           key=lambda k: self._metrics_cache[k].capture_time)
            del self._metrics_cache[oldest_key]

        self._metrics_cache[transaction_num] = metrics

    def _create_fallback_metrics(self, transaction_num: int, transaction_id: str) -> SimplexMetrics:
        """Cr√©e m√©triques fallback en cas d'erreur capture"""
        return SimplexMetrics(
            transaction_num=transaction_num,
            transaction_id=transaction_id,
            vertices_count=5,  # Fallback vers mock original
            constraints_count=3,
            algorithm_steps=4,
            optimal_coordinates=[0.33, 0.33, 0.33],
            optimal_value=1.0,
            solution_status=SolutionStatus.UNKNOWN,
            warm_start_used=False,
            cross_validation_passed=False,
            enumeration_time_ms=0.0,
            simplex_solve_time_ms=0.0
        )


# Instance globale pour utilisation par DAG et API SVG
validation_collector = ValidationDataCollector()


def get_validation_collector() -> ValidationDataCollector:
    """
    Accesseur global collecteur validation

    Returns:
        Instance ValidationDataCollector configur√©e
    """
    return validation_collector